{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 Assignment 2\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices: tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "from tensorflow import keras\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Flatten\n",
    "#from tensorflow.keras.layers import Dense\n",
    "#from tensorflow.keras.layers import Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.random.set_seed(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a choice of dataset, mnist (0) or fashion_mnist (1)\n",
    "choice = 0\n",
    "\n",
    "if choice == 0:\n",
    "    dataset = keras.datasets.mnist\n",
    "    class_names = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "elif choice == 1:\n",
    "    dataset = keras.datasets.fashion_mnist\n",
    "    class_names_f = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\n",
    "                     \"Bag\",\"Ankle Boot\"]\n",
    "    \n",
    "(X_train_full, y_train_full), (X_test, y_test) = dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing step\n",
    "\n",
    "k = 5000\n",
    "mx = np.max(X_train_full)\n",
    "\n",
    "X_valid, X_train = X_train_full[:k] / mx, X_train_full[k:] / mx\n",
    "y_valid, y_train = y_train_full[:k], y_train_full[k:]\n",
    "\n",
    "# format CNN\n",
    "X_test_, X_valid_, X_train_ = np.expand_dims(X_test, axis=-1), np.expand_dims(X_valid, axis=-1),np.expand_dims(X_train, axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the settings for the MLP / CNN \n",
    "\n",
    "# Settings regarding model structure and optimization\n",
    "settings_1 = [(0,0,0,0), # base line model: MLP / CNN\n",
    "              (1,0,0,0), # optimizer: ADAM\n",
    "              (0,1,0,0), # dropout: including / excluding\n",
    "              (0,0,1,0), # add another layer to the model\n",
    "              (0,0,0,1)] # remove layer from the model\n",
    "\n",
    "# Settings regarding the activation functions and the initialization\n",
    "settings_2 = [(\"tanh\",\"glorot_uniform\"),\n",
    "              (\"tanh\",\"glorot_normal\"),\n",
    "              (\"relu\",\"he_uniform\"),\n",
    "              (\"relu\",\"he_normal\"),\n",
    "              (\"selu\",\"lecun_uniform\"),\n",
    "              (\"selu\",\"lecun_normal\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Setting: 0\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.6080 - accuracy: 0.8450 - val_loss: 0.3084 - val_accuracy: 0.9130\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.2890 - accuracy: 0.9170 - val_loss: 0.2392 - val_accuracy: 0.9328\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.2362 - accuracy: 0.9322 - val_loss: 0.2045 - val_accuracy: 0.9456\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.2020 - accuracy: 0.9421 - val_loss: 0.1769 - val_accuracy: 0.9514\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.1757 - accuracy: 0.9494 - val_loss: 0.1568 - val_accuracy: 0.9584\n",
      "Epoch 6/100\n",
      "25472/55000 [============>.................] - ETA: 1s - loss: 0.1579 - accuracy: 0.9549"
     ]
    }
   ],
   "source": [
    "# MLP settings 1.\n",
    "\n",
    "runs = 10\n",
    "output_1 = np.zeros([runs, 3*len(settings_1)])\n",
    "\n",
    "for ix, s in enumerate(settings_1):\n",
    "    print(\"Model Setting: \"+str(ix))\n",
    "    \n",
    "    for i in range(runs):\n",
    "        \n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.Flatten(input_shape=X_train.shape[1:3]))\n",
    "        \n",
    "        if not s[1]:\n",
    "            model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"glorot_uniform\"))\n",
    "            if s[2]:\n",
    "                model.add(keras.layers.Dense(200, activation=\"relu\", kernel_initializer=\"glorot_uniform\"))\n",
    "            if not s[3]:\n",
    "                model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"glorot_uniform\"))\n",
    "            model.add(keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"))\n",
    "        else:\n",
    "            model.add(keras.layers.Dropout(rate=0.2))\n",
    "            model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"glorot_uniform\"))\n",
    "            model.add(keras.layers.Dropout(rate=0.2))\n",
    "            if s[2]:\n",
    "                model.add(keras.layers.Dense(200, activation=\"relu\", kernel_initializer=\"glorot_uniform\"))\n",
    "                model.add(keras.layers.Dropout(rate=0.2))\n",
    "            if not s[3]:\n",
    "                model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"glorot_uniform\"))\n",
    "                model.add(keras.layers.Dropout(rate=0.2))\n",
    "            model.add(keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"))\n",
    "            model.add(keras.layers.Dropout(rate=0.2))\n",
    "        \n",
    "        opt = \"sgd\"\n",
    "        if s[0]: \n",
    "            opt = \"adam\"\n",
    "        \n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                      optimizer=opt,\n",
    "                      metrics=[\"accuracy\"])\n",
    "        \n",
    "        print(X_train.shape)\n",
    "        history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid,y_valid),\n",
    "                            callbacks=[keras.callbacks.EarlyStopping(patience=6)])\n",
    "        \n",
    "        output_1[i,ix*3] = model.evaluate(X_test, y_test)[1]\n",
    "        output_1[i,3*ix+1] = len(history.history['loss'])\n",
    "        output_1[i,3*ix+2] = history.history['val_accuracy'][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 15)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the obtained output\n",
    "np.save('output_1.npy', output_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: tanh. Initialization: glorot_uniform\n",
      "Model iteration: 0\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.5539 - accuracy: 0.8590 - val_loss: 0.3280 - val_accuracy: 0.9100\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.3193 - accuracy: 0.9089 - val_loss: 0.2718 - val_accuracy: 0.9254\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 0.2948 - accuracy: 0.9154\n",
      "Model iteration: 1\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.5465 - accuracy: 0.8608 - val_loss: 0.3278 - val_accuracy: 0.9114\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.3197 - accuracy: 0.9083 - val_loss: 0.2722 - val_accuracy: 0.9246\n",
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.2942 - accuracy: 0.9123\n",
      "Activation: tanh. Initialization: glorot_normal\n",
      "Model iteration: 0\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 3s 50us/sample - loss: 0.5603 - accuracy: 0.8548 - val_loss: 0.3317 - val_accuracy: 0.9116\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.3190 - accuracy: 0.9092 - val_loss: 0.2711 - val_accuracy: 0.9264\n",
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.2908 - accuracy: 0.9164\n",
      "Model iteration: 1\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.5371 - accuracy: 0.8595 - val_loss: 0.3225 - val_accuracy: 0.9100\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.3151 - accuracy: 0.9100 - val_loss: 0.2662 - val_accuracy: 0.9276\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 0.2973 - accuracy: 0.9141\n",
      "Activation: relu. Initialization: he_uniform\n",
      "Model iteration: 0\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.5657 - accuracy: 0.8525 - val_loss: 0.2968 - val_accuracy: 0.9184\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.2796 - accuracy: 0.9201 - val_loss: 0.2328 - val_accuracy: 0.9362\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 30.5166 - accuracy: 0.9335\n",
      "Model iteration: 1\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 3s 50us/sample - loss: 0.5663 - accuracy: 0.8515 - val_loss: 0.3004 - val_accuracy: 0.9174\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 3s 47us/sample - loss: 0.2865 - accuracy: 0.9186 - val_loss: 0.2353 - val_accuracy: 0.9372\n",
      "10000/10000 [==============================] - 0s 37us/sample - loss: 31.8536 - accuracy: 0.9289\n",
      "Activation: relu. Initialization: he_normal\n",
      "Model iteration: 0\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 3s 50us/sample - loss: 0.5783 - accuracy: 0.8487 - val_loss: 0.2896 - val_accuracy: 0.9174\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.2781 - accuracy: 0.9197 - val_loss: 0.2256 - val_accuracy: 0.9384\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 30.0518 - accuracy: 0.9329\n",
      "Model iteration: 1\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 3s 49us/sample - loss: 0.5878 - accuracy: 0.8442 - val_loss: 0.3007 - val_accuracy: 0.9158\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 3s 47us/sample - loss: 0.2829 - accuracy: 0.9183 - val_loss: 0.2341 - val_accuracy: 0.9386\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 30.9938 - accuracy: 0.9304\n",
      "Activation: selu. Initialization: lecun_uniform\n",
      "Model iteration: 0\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.4454 - accuracy: 0.8777 - val_loss: 0.2927 - val_accuracy: 0.9186\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 3s 49us/sample - loss: 0.2960 - accuracy: 0.9147 - val_loss: 0.2588 - val_accuracy: 0.9298\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 85.7275 - accuracy: 0.5345\n",
      "Model iteration: 1\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.4473 - accuracy: 0.8773 - val_loss: 0.2935 - val_accuracy: 0.9196\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.2937 - accuracy: 0.9151 - val_loss: 0.2565 - val_accuracy: 0.9292\n",
      "10000/10000 [==============================] - 0s 36us/sample - loss: 90.5713 - accuracy: 0.4899\n",
      "Activation: selu. Initialization: lecun_normal\n",
      "Model iteration: 0\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.4459 - accuracy: 0.8775 - val_loss: 0.2901 - val_accuracy: 0.9180\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 3s 49us/sample - loss: 0.2936 - accuracy: 0.9149 - val_loss: 0.2546 - val_accuracy: 0.9296\n",
      "10000/10000 [==============================] - 0s 37us/sample - loss: 18.8920 - accuracy: 0.8121\n",
      "Model iteration: 1\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 3s 50us/sample - loss: 0.4465 - accuracy: 0.8775 - val_loss: 0.2921 - val_accuracy: 0.9158\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.2925 - accuracy: 0.9156 - val_loss: 0.2542 - val_accuracy: 0.9302\n",
      "10000/10000 [==============================] - 0s 37us/sample - loss: 28.6478 - accuracy: 0.7318\n"
     ]
    }
   ],
   "source": [
    "# MLP settings 2\n",
    "\n",
    "runs = 2\n",
    "output_2 = np.zeros([runs, 3*len(settings_2)])\n",
    "\n",
    "for ix, s in enumerate(settings_2):\n",
    "    print(\"Activation: \"+s[0]+\". Initialization: \"+s[1])\n",
    "    \n",
    "    for i in range(runs):\n",
    "        print(\"Model iteration: \"+str(i))\n",
    "        model = keras.models.Sequential([\n",
    "            keras.layers.Flatten(input_shape=X_train.shape[1:3]),\n",
    "            keras.layers.Dense(300, activation=s[0], kernel_initializer=s[1]),\n",
    "            keras.layers.Dense(100, activation=s[0], kernel_initializer=s[1]),\n",
    "            keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
    "        ])\n",
    "        \n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                      optimizer=\"sgd\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "        \n",
    "        print(X_train.shape)\n",
    "        history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid,y_valid),\n",
    "                            callbacks=[keras.callbacks.EarlyStopping(patience=6)])\n",
    "        \n",
    "        output_2[i,ix*3] = model.evaluate(X_test, y_test)[1]\n",
    "        output_2[i,3*ix+1] = len(history.history['loss'])\n",
    "        output_2[i,3*ix+2] = history.history['val_accuracy'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the obtained output\n",
    "np.save('output_2.npy', output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Setting: 0\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 7s 133us/sample - loss: 1.1654 - accuracy: 0.6051 - val_loss: 0.1770 - val_accuracy: 0.9508\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.2801 - accuracy: 0.9208 - val_loss: 0.0804 - val_accuracy: 0.9774\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.1803 - accuracy: 0.9517 - val_loss: 0.0605 - val_accuracy: 0.9830\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.1385 - accuracy: 0.9636 - val_loss: 0.0580 - val_accuracy: 0.9844\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.1146 - accuracy: 0.9701 - val_loss: 0.0487 - val_accuracy: 0.9862\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0983 - accuracy: 0.9748 - val_loss: 0.0534 - val_accuracy: 0.9858\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0858 - accuracy: 0.9785 - val_loss: 0.0448 - val_accuracy: 0.9902\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0739 - accuracy: 0.9810 - val_loss: 0.0407 - val_accuracy: 0.9908\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0646 - accuracy: 0.9837 - val_loss: 0.0457 - val_accuracy: 0.9888\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.0621 - accuracy: 0.9841 - val_loss: 0.0405 - val_accuracy: 0.9920\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0566 - accuracy: 0.9855 - val_loss: 0.0368 - val_accuracy: 0.9922\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0527 - accuracy: 0.9867 - val_loss: 0.0344 - val_accuracy: 0.9920\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0467 - accuracy: 0.9880 - val_loss: 0.0434 - val_accuracy: 0.9922\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0437 - accuracy: 0.9893 - val_loss: 0.0364 - val_accuracy: 0.9924\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0405 - accuracy: 0.9892 - val_loss: 0.0417 - val_accuracy: 0.9924\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0379 - accuracy: 0.9901 - val_loss: 0.0398 - val_accuracy: 0.9916\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0332 - accuracy: 0.9919 - val_loss: 0.0390 - val_accuracy: 0.9926\n",
      "120.90296053886414\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 6.4093 - accuracy: 0.9932\n",
      "Model Setting: 1\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 8s 146us/sample - loss: 0.4052 - accuracy: 0.8742 - val_loss: 0.0881 - val_accuracy: 0.9830\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 7s 136us/sample - loss: 0.1229 - accuracy: 0.9713 - val_loss: 0.0591 - val_accuracy: 0.9870\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 7s 136us/sample - loss: 0.0990 - accuracy: 0.9770 - val_loss: 0.0994 - val_accuracy: 0.9820\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.0742 - accuracy: 0.9830 - val_loss: 0.0524 - val_accuracy: 0.9904\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.0619 - accuracy: 0.9861 - val_loss: 0.0440 - val_accuracy: 0.9906\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.0566 - accuracy: 0.9876 - val_loss: 0.0514 - val_accuracy: 0.9908\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.0500 - accuracy: 0.9893 - val_loss: 0.0444 - val_accuracy: 0.9920\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.0419 - accuracy: 0.9903 - val_loss: 0.0416 - val_accuracy: 0.9922\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.0433 - accuracy: 0.9900 - val_loss: 0.0532 - val_accuracy: 0.9912\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 7s 135us/sample - loss: 0.0394 - accuracy: 0.9914 - val_loss: 0.0518 - val_accuracy: 0.9926\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.0374 - accuracy: 0.9917 - val_loss: 0.0414 - val_accuracy: 0.9928\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 7s 135us/sample - loss: 0.0358 - accuracy: 0.9920 - val_loss: 0.0527 - val_accuracy: 0.9936\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 7s 135us/sample - loss: 0.0354 - accuracy: 0.9921 - val_loss: 0.0481 - val_accuracy: 0.9934\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.0341 - accuracy: 0.9923 - val_loss: 0.0516 - val_accuracy: 0.9926\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.0282 - accuracy: 0.9936 - val_loss: 0.0961 - val_accuracy: 0.9854\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 7s 135us/sample - loss: 0.0369 - accuracy: 0.9920 - val_loss: 0.0720 - val_accuracy: 0.9910\n",
      "119.1413197517395\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 20.8739 - accuracy: 0.9883\n",
      "Model Setting: 2\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 7s 132us/sample - loss: 0.7531 - accuracy: 0.7710 - val_loss: 0.1521 - val_accuracy: 0.9512\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.1073 - accuracy: 0.9665 - val_loss: 0.0825 - val_accuracy: 0.9742\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.0704 - accuracy: 0.9778 - val_loss: 0.0683 - val_accuracy: 0.9798\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.0539 - accuracy: 0.9829 - val_loss: 0.0540 - val_accuracy: 0.9836\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.0437 - accuracy: 0.9861 - val_loss: 0.0434 - val_accuracy: 0.9884\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0354 - accuracy: 0.9885 - val_loss: 0.0387 - val_accuracy: 0.9892\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.0295 - accuracy: 0.9906 - val_loss: 0.0452 - val_accuracy: 0.9866\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.0351 - val_accuracy: 0.9918\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0378 - val_accuracy: 0.9902\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0349 - val_accuracy: 0.9898\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0358 - val_accuracy: 0.9900\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 7s 127us/sample - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0347 - val_accuracy: 0.9908\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0350 - val_accuracy: 0.9902\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.0405 - val_accuracy: 0.9884\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0417 - val_accuracy: 0.9904\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0389 - val_accuracy: 0.9904\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0428 - val_accuracy: 0.9900\n",
      "120.53270745277405\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 7.1440 - accuracy: 0.9895\n",
      "Model Setting: 3\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 13s 235us/sample - loss: 1.4803 - accuracy: 0.4863 - val_loss: 0.2441 - val_accuracy: 0.9262\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 13s 228us/sample - loss: 0.3107 - accuracy: 0.9144 - val_loss: 0.1073 - val_accuracy: 0.9718\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 13s 230us/sample - loss: 0.1745 - accuracy: 0.9555 - val_loss: 0.0697 - val_accuracy: 0.9804\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 13s 229us/sample - loss: 0.1253 - accuracy: 0.9685 - val_loss: 0.0563 - val_accuracy: 0.9854\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 12s 226us/sample - loss: 0.1021 - accuracy: 0.9748 - val_loss: 0.0625 - val_accuracy: 0.9848\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 13s 227us/sample - loss: 0.0845 - accuracy: 0.9793 - val_loss: 0.0644 - val_accuracy: 0.9882\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 13s 230us/sample - loss: 0.0701 - accuracy: 0.9830 - val_loss: 0.0533 - val_accuracy: 0.9890\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 13s 230us/sample - loss: 0.0596 - accuracy: 0.9853 - val_loss: 0.0579 - val_accuracy: 0.9870\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 12s 227us/sample - loss: 0.0530 - accuracy: 0.9870 - val_loss: 0.0465 - val_accuracy: 0.9912\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 13s 229us/sample - loss: 0.0453 - accuracy: 0.9889 - val_loss: 0.0492 - val_accuracy: 0.9904\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 13s 227us/sample - loss: 0.0429 - accuracy: 0.9896 - val_loss: 0.0419 - val_accuracy: 0.9910\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 13s 228us/sample - loss: 0.0372 - accuracy: 0.9915 - val_loss: 0.0459 - val_accuracy: 0.9914\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 13s 229us/sample - loss: 0.0315 - accuracy: 0.9915 - val_loss: 0.0397 - val_accuracy: 0.9924\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 13s 229us/sample - loss: 0.0299 - accuracy: 0.9921 - val_loss: 0.0464 - val_accuracy: 0.9914\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 13s 229us/sample - loss: 0.0263 - accuracy: 0.9932 - val_loss: 0.0467 - val_accuracy: 0.9914\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 13s 228us/sample - loss: 0.0273 - accuracy: 0.9939 - val_loss: 0.0397 - val_accuracy: 0.9920\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 13s 228us/sample - loss: 0.0244 - accuracy: 0.9943 - val_loss: 0.0463 - val_accuracy: 0.9914\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 12s 227us/sample - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.0414 - val_accuracy: 0.9922\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 13s 228us/sample - loss: 0.0186 - accuracy: 0.9956 - val_loss: 0.0422 - val_accuracy: 0.9922\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 13s 229us/sample - loss: 0.0181 - accuracy: 0.9954 - val_loss: 0.0478 - val_accuracy: 0.9922\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 13s 229us/sample - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.0503 - val_accuracy: 0.9924\n",
      "264.3157980442047\n",
      "10000/10000 [==============================] - 1s 89us/sample - loss: 12.0414 - accuracy: 0.9917\n",
      "Model Setting: 4\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 1.0699 - accuracy: 0.6431 - val_loss: 0.1940 - val_accuracy: 0.9462\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.3119 - accuracy: 0.9122 - val_loss: 0.1091 - val_accuracy: 0.9696\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.2058 - accuracy: 0.9441 - val_loss: 0.0795 - val_accuracy: 0.9762\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.1607 - accuracy: 0.9567 - val_loss: 0.0692 - val_accuracy: 0.9806\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.1382 - accuracy: 0.9634 - val_loss: 0.0610 - val_accuracy: 0.9836\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.1202 - accuracy: 0.9684 - val_loss: 0.0594 - val_accuracy: 0.9844\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.1080 - accuracy: 0.9719 - val_loss: 0.0621 - val_accuracy: 0.9862\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.0976 - accuracy: 0.9748 - val_loss: 0.0530 - val_accuracy: 0.9874\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 5s 94us/sample - loss: 0.0888 - accuracy: 0.9766 - val_loss: 0.0538 - val_accuracy: 0.9866\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.0852 - accuracy: 0.9782 - val_loss: 0.0574 - val_accuracy: 0.9862\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 5s 94us/sample - loss: 0.0758 - accuracy: 0.9808 - val_loss: 0.0548 - val_accuracy: 0.9878\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.0726 - accuracy: 0.9809 - val_loss: 0.0461 - val_accuracy: 0.9896\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.0493 - val_accuracy: 0.9890\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.0653 - accuracy: 0.9830 - val_loss: 0.0489 - val_accuracy: 0.9882\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.0596 - accuracy: 0.9846 - val_loss: 0.0595 - val_accuracy: 0.9878\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.0582 - accuracy: 0.9849 - val_loss: 0.0450 - val_accuracy: 0.9900\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 5s 94us/sample - loss: 0.0596 - accuracy: 0.9849 - val_loss: 0.0433 - val_accuracy: 0.9912\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.0518 - accuracy: 0.9865 - val_loss: 0.0489 - val_accuracy: 0.9898\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.0497 - accuracy: 0.9871 - val_loss: 0.0430 - val_accuracy: 0.9918\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.0509 - accuracy: 0.9867 - val_loss: 0.0438 - val_accuracy: 0.9908\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.0446 - accuracy: 0.9885 - val_loss: 0.0438 - val_accuracy: 0.9910\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.0409 - accuracy: 0.9889 - val_loss: 0.0464 - val_accuracy: 0.9906\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.0436 - accuracy: 0.9884 - val_loss: 0.0445 - val_accuracy: 0.9916\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 5s 94us/sample - loss: 0.0416 - accuracy: 0.9892 - val_loss: 0.0439 - val_accuracy: 0.9908\n",
      "125.76718163490295\n",
      "10000/10000 [==============================] - 1s 50us/sample - loss: 5.5605 - accuracy: 0.9921\n"
     ]
    }
   ],
   "source": [
    "# CNN settings 1\n",
    "\n",
    "runs = 1\n",
    "output_3 = np.zeros([runs, 3*len(settings_1)])\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "for ix, s in enumerate(settings_1):\n",
    "    print(\"Model Setting: \"+str(ix))\n",
    "    \n",
    "    for i in range(runs):\n",
    "        \n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\", input_shape=[28, 28, 1]))\n",
    "        model.add(keras.layers.MaxPooling2D(2))\n",
    "        model.add(keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "        model.add(keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "        model.add(keras.layers.MaxPooling2D(2))\n",
    "        if not s[3]:\n",
    "            model.add(keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "            model.add(keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n",
    "            model.add(keras.layers.MaxPooling2D(2))\n",
    "        if s[2]:\n",
    "            model.add(keras.layers.Conv2D(512, 3, activation=\"relu\", padding=\"same\"))\n",
    "            model.add(keras.layers.Conv2D(512, 3, activation=\"relu\", padding=\"same\"))\n",
    "            model.add(keras.layers.MaxPooling2D(2))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        \n",
    "        if not s[1]:\n",
    "            model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "            model.add(keras.layers.Dropout(0.5))\n",
    "            model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "            model.add(keras.layers.Dropout(0.5))\n",
    "            model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "            \n",
    "        else:\n",
    "            model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "            model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "            model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "        \n",
    "        \n",
    "        \n",
    "        opt = \"sgd\"\n",
    "        if s[0]: \n",
    "            opt = \"adam\"\n",
    "        \n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                      optimizer=opt,\n",
    "                      metrics=[\"accuracy\"])\n",
    "        \n",
    "        t1 = time.time()\n",
    "        history = model.fit(X_train_, y_train, epochs=100, validation_data=(X_valid_,y_valid),\n",
    "                            callbacks=[keras.callbacks.EarlyStopping(patience=5)])\n",
    "        print(time.time() - t1)\n",
    "        \n",
    "        output_3[i,ix*3] = model.evaluate(X_test_, y_test)[1]\n",
    "        output_3[i,3*ix+1] = len(history.history['loss'])\n",
    "        output_3[i,3*ix+2] = history.history['val_accuracy'][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the obtained output\n",
    "np.save('output_3.npy', output_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: tanh. Initialization: glorot_uniform\n",
      "Model iteration: 0\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 9s 158us/sample - loss: 0.4939 - accuracy: 0.8619 - val_loss: 0.0992 - val_accuracy: 0.9708\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.1525 - accuracy: 0.9586 - val_loss: 0.0613 - val_accuracy: 0.9814\n",
      "10000/10000 [==============================] - 1s 68us/sample - loss: 0.4164 - accuracy: 0.8573\n",
      "Activation: tanh. Initialization: glorot_normal\n",
      "Model iteration: 0\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.5212 - accuracy: 0.8507 - val_loss: 0.0957 - val_accuracy: 0.9730\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.1546 - accuracy: 0.9584 - val_loss: 0.0604 - val_accuracy: 0.9826\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1185 - accuracy: 0.9637\n",
      "Activation: relu. Initialization: he_uniform\n",
      "Model iteration: 0\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.7443 - accuracy: 0.7557 - val_loss: 0.0978 - val_accuracy: 0.9740\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.2237 - accuracy: 0.9370 - val_loss: 0.0606 - val_accuracy: 0.9838\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 9.5084 - accuracy: 0.9852\n",
      "Activation: relu. Initialization: he_normal\n",
      "Model iteration: 0\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.7024 - accuracy: 0.7681 - val_loss: 0.1006 - val_accuracy: 0.9736\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.2153 - accuracy: 0.9382 - val_loss: 0.0655 - val_accuracy: 0.9814\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 10.4225 - accuracy: 0.9814\n",
      "Activation: selu. Initialization: lecun_uniform\n",
      "Model iteration: 0\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 7s 135us/sample - loss: 0.3120 - accuracy: 0.9065 - val_loss: 0.0694 - val_accuracy: 0.9804\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.1105 - accuracy: 0.9671 - val_loss: 0.0506 - val_accuracy: 0.9856\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 6.2978 - accuracy: 0.6569\n",
      "Activation: selu. Initialization: lecun_normal\n",
      "Model iteration: 0\n",
      "(55000, 28, 28)\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.3228 - accuracy: 0.9039 - val_loss: 0.0674 - val_accuracy: 0.9828\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.1118 - accuracy: 0.9671 - val_loss: 0.0463 - val_accuracy: 0.9872\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 14.5266 - accuracy: 0.4893\n"
     ]
    }
   ],
   "source": [
    "# CNN settings 2\n",
    "\n",
    "runs = 1\n",
    "output_4 = np.zeros([runs, 3*len(settings_2)])\n",
    "\n",
    "for ix, s in enumerate(settings_2):\n",
    "    print(\"Activation: \"+s[0]+\". Initialization: \"+s[1])\n",
    "    \n",
    "    for i in range(runs):\n",
    "        print(\"Model iteration: \"+str(i))\n",
    "        model = keras.models.Sequential([\n",
    "            keras.layers.Conv2D(64, 7, activation=s[0], kernel_initializer=s[1], padding=\"same\", \n",
    "                                input_shape=[28, 28, 1]),\n",
    "            keras.layers.MaxPooling2D(2),\n",
    "            keras.layers.Conv2D(128, 3, activation=s[0], kernel_initializer=s[1], padding=\"same\"),\n",
    "            keras.layers.Conv2D(128, 3, activation=s[0], kernel_initializer=s[1], padding=\"same\"),\n",
    "            keras.layers.MaxPooling2D(2),\n",
    "            keras.layers.Conv2D(256, 3, activation=s[0], kernel_initializer=s[1], padding=\"same\"),\n",
    "            keras.layers.Conv2D(256, 3, activation=s[0], kernel_initializer=s[1], padding=\"same\"),\n",
    "            keras.layers.MaxPooling2D(2),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(128, activation=s[0], kernel_initializer=s[1]),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(64, activation=s[0], kernel_initializer=s[1]),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
    "        ])\n",
    "        \n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                      optimizer=\"sgd\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "        \n",
    "        history = model.fit(X_train_, y_train, epochs=2, validation_data=(X_valid_,y_valid),\n",
    "                            callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "        \n",
    "        output_4[i,ix*3] = model.evaluate(X_test_, y_test)[1]\n",
    "        output_4[i,3*ix+1] = len(history.history['loss'])\n",
    "        output_4[i,3*ix+2] = history.history['val_accuracy'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the obtained output\n",
    "np.save('output_4.npy', output_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
